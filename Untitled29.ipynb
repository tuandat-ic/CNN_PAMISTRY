{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JttOfrEhgnjC"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "src_path = \"/content/drive/MyDrive/Palmistry\"\n",
        "\n",
        "# Ki·ªÉm tra th∆∞ m·ª•c\n",
        "print(\"Classes:\", os.listdir(src_path))\n",
        "\n",
        "# 2) Import + t·∫°o generator v·ªõi resize 60x60 v√† t√°ch validation 20%\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.5,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    src_path,\n",
        "    target_size=(60, 60),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training',   # train subset\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    src_path,\n",
        "    target_size=(60, 60),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',  # validation subset\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# 3) Build CNN model\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "num_classes = train_generator.num_classes\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(60, 60, 3)),\n",
        "    layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 4) Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=200\n",
        ")\n",
        "model.save('final_model.h5')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bgA9oDSDgsna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Upload ·∫£nh\n",
        "uploaded = files.upload()\n",
        "img_path = list(uploaded.keys())[0]\n",
        "\n",
        "# ƒê·ªçc + resize v·ªÅ 60x60\n",
        "img = cv2.imread(img_path)\n",
        "img_resized = cv2.resize(img, (60, 60))\n",
        "img_array = img_resized / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# D·ª± ƒëo√°n\n",
        "pred = model.predict(img_array)\n",
        "class_index = np.argmax(pred)\n",
        "confidence = np.max(pred)\n",
        "\n",
        "labels = list(train_generator.class_indices.keys())\n",
        "print(\"D·ª± ƒëo√°n:\", labels[class_index], \"- ƒê·ªô tin c·∫≠y:\", confidence)\n",
        "\n",
        "# Hi·ªÉn th·ªã ·∫£nh\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f\"D·ª± ƒëo√°n: {labels[class_index]} ({confidence:.2f})\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oSke53a1keU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load model CNN nh·∫≠n di·ªán ch·ªâ tay\n",
        "model_path = 'final_model.h5'  # ƒë·ªïi theo ƒë∆∞·ªùng d·∫´n model c·ªßa b·∫°n\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Nh√£n c√°c lo·∫°i ch·ªâ tay (th·ª© t·ª± ph·∫£i tr√πng v·ªõi model training)\n",
        "palm_labels = [\n",
        "    \"Ch·ªâ tay ch·ªØ M\",\n",
        "    \"Ch·ªâ tay ch·ªØ nh·∫•t\",\n",
        "    \"Ch·ªâ tay ƒëu√¥i c√°\",\n",
        "    \"Ch·ªâ tay m·∫Øt ph∆∞·ª£ng\",\n",
        "    \"Ch·ªâ tay th·ªèi v√†ng\"\n",
        "]\n",
        "\n",
        "# Th√¥ng tin chi ti·∫øt v·ªÅ t·ª´ng lo·∫°i ch·ªâ tay\n",
        "palmistry_info = {\n",
        "    \"Ch·ªâ tay ch·ªØ M\": \"Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay ch·ªØ M th∆∞·ªùng ƒë∆∞·ª£c cho l√† c√≥ t√†i nƒÉng ƒë·∫∑c bi·ªát, th√¥ng minh, v√† may m·∫Øn. H·ªç c√≥ kh·∫£ nƒÉng l√£nh ƒë·∫°o, tr·ª±c gi√°c t·ªët v√† th∆∞·ªùng ƒë·∫°t ƒë∆∞·ª£c th√†nh c√¥ng l·ªõn trong s·ª± nghi·ªáp v√† cu·ªôc s·ªëng.\",\n",
        "    \"Ch·ªâ tay ch·ªØ nh·∫•t\": \"Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay ch·ªØ Nh·∫•t th∆∞·ªùng c√≥ t√≠nh c√°ch m·∫°nh m·∫Ω v√† quy·∫øt ƒëo√°n. H·ªç c√≥ kh·∫£ nƒÉng t·∫≠p trung cao ƒë·ªô v√† th∆∞·ªùng ƒë·∫°t ƒë∆∞·ª£c th√†nh c√¥ng trong nh·ªØng lƒ©nh v·ª±c ƒë√≤i h·ªèi s·ª± ki√™n tr√¨ v√† quy·∫øt t√¢m. Tuy nhi√™n, h·ªç c≈©ng c√≥ th·ªÉ g·∫∑p kh√≥ khƒÉn trong vi·ªác c√¢n b·∫±ng gi·ªØa l√Ω tr√≠ v√† c·∫£m x√∫c.\",\n",
        "    \"Ch·ªâ tay ƒëu√¥i c√°\": \"Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay ƒëu√¥i c√° th∆∞·ªùng ƒë∆∞·ª£c coi l√† c√≥ may m·∫Øn ƒë·∫∑c bi·ªát v√† th∆∞·ªùng g·∫∑p ƒë∆∞·ª£c nhi·ªÅu c∆° h·ªôi t·ªët trong cu·ªôc s·ªëng. H·ªç c√≥ kh·∫£ nƒÉng v∆∞·ª£t qua kh√≥ khƒÉn v√† ƒë·∫°t ƒë∆∞·ª£c th√†nh c√¥ng l·ªõn.\",\n",
        "    \"Ch·ªâ tay m·∫Øt ph∆∞·ª£ng\": \"Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay m·∫Øt ph∆∞·ª£ng th∆∞·ªùng c√≥ tr·ª±c gi√°c t·ªët, tr√≠ tu·ªá cao v√† kh·∫£ nƒÉng nh√¨n xa tr√¥ng r·ªông. H·ªç th∆∞·ªùng ƒë∆∞·ª£c qu√Ω nh√¢n ph√π tr·ª£ v√† c√≥ nhi·ªÅu c∆° h·ªôi th√†nh c√¥ng trong cu·ªôc s·ªëng.\",\n",
        "    \"Ch·ªâ tay th·ªèi v√†ng\": \"Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay th·ªèi v√†ng th∆∞·ªùng ƒë∆∞·ª£c cho l√† c√≥ t√†i l·ªôc, th·ªãnh v∆∞·ª£ng v√† th√†nh c√¥ng trong s·ª± nghi·ªáp. H·ªç c√≥ kh·∫£ nƒÉng qu·∫£n l√Ω t√†i ch√≠nh t·ªët v√† th∆∞·ªùng g·∫∑p may m·∫Øn trong kinh doanh.\",\n",
        "}\n",
        "\n",
        "# H√†m d·ª± ƒëo√°n\n",
        "def predict_palm(img):\n",
        "    img_resized = img.convert(\"RGB\").resize((60,60))  # Resize v·ªÅ 60x60 (theo model b·∫°n train)\n",
        "    x = np.array(img_resized)/255.0\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    preds = model.predict(x)\n",
        "    class_idx = np.argmax(preds)\n",
        "    confidence = preds[0][class_idx]\n",
        "\n",
        "    palm_type = palm_labels[class_idx]\n",
        "    description = palmistry_info.get(palm_type, \"Ch∆∞a c√≥ th√¥ng tin.\")\n",
        "    return img_resized, palm_type, round(confidence*100, 2), description\n",
        "\n",
        "# H√†m reset\n",
        "def reset_image():\n",
        "    return None, None, \"\", \"\", \"\"\n",
        "\n",
        "# CSS giao di·ªán huy·ªÅn b√≠\n",
        "css_style = \"\"\"\n",
        "body {\n",
        "    background: radial-gradient(circle at top, #1c0033, #0a0014);\n",
        "    font-family: 'Poppins', sans-serif;\n",
        "    color: #f3e5f5;\n",
        "}\n",
        "h1 {\n",
        "    color: #ffffff;  /* tr·∫Øng s√°ng thay v√¨ t√≠m nh·∫°t */\n",
        "    text-shadow: 0px 0px 20px #e1bee7, 0px 0px 40px #ba68c8;\n",
        "    font-family: 'Orbitron', sans-serif;\n",
        "    font-size: 42px;\n",
        "    font-weight: bold;\n",
        "    letter-spacing: 2px;\n",
        "}\n",
        "#predict-btn {\n",
        "    background: linear-gradient(45deg, #6a1b9a, #311b92);\n",
        "    color: #fff;\n",
        "    font-weight: bold;\n",
        "    font-size: 18px;\n",
        "    border-radius: 25px;\n",
        "    box-shadow: 0px 0px 10px #7e57c2;\n",
        "}\n",
        "#reset-btn {\n",
        "    background: linear-gradient(45deg, #004d40, #1a237e);\n",
        "    color: #fff;\n",
        "    font-weight: bold;\n",
        "    font-size: 18px;\n",
        "    border-radius: 25px;\n",
        "    box-shadow: 0px 0px 10px #26a69a;\n",
        "}\n",
        ".gr-button {padding: 12px 25px;}\n",
        ".gr-box {\n",
        "    border: 2px solid #7e57c2;\n",
        "    border-radius: 20px;\n",
        "    padding: 15px;\n",
        "    background-color: rgba(20, 0, 40, 0.85);\n",
        "    color: #e1bee7;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Giao di·ªán Gradio\n",
        "with gr.Blocks(css=css_style) as demo:\n",
        "    gr.Markdown(\"<h1 style='text-align:center;'>üîÆ ·ª®ng d·ª•ng b√≥i ch·ªâ tay online ‚úã</h1>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            img_input = gr.Image(type=\"pil\", label=\"‚ú® Ch·ªçn ·∫£nh ho·∫∑c k√©o th·∫£ ·∫£nh ch·ªâ tay ‚ú®\")\n",
        "            btn_predict = gr.Button(\"üîÆ Nh·∫≠n di·ªán ‚úã\", elem_id=\"predict-btn\")\n",
        "            btn_reset = gr.Button(\"üîÑ Ch·ªçn ·∫£nh kh√°c\", elem_id=\"reset-btn\")\n",
        "        with gr.Column():\n",
        "            label_output = gr.Textbox(label=\"üîÆ Lo·∫°i ch·ªâ tay d·ª± ƒëo√°n\", interactive=False)\n",
        "            confidence_output = gr.Textbox(label=\"üìä ƒê·ªô ch√≠nh x√°c (%)\", interactive=False)\n",
        "            description_output = gr.Textbox(label=\"üìñ Mi√™u t·∫£ chi ti·∫øt\", interactive=False, lines=6)\n",
        "\n",
        "    # N√∫t d·ª± ƒëo√°n\n",
        "    btn_predict.click(\n",
        "        predict_palm,\n",
        "        inputs=img_input,\n",
        "        outputs=[img_resized_output, label_output, confidence_output, description_output]\n",
        "    )\n",
        "\n",
        "    # N√∫t reset\n",
        "    btn_reset.click(\n",
        "        reset_image,\n",
        "        inputs=None,\n",
        "        outputs=[img_input, img_resized_output, label_output, confidence_output, description_output]\n",
        "    )\n",
        "\n",
        "# Ch·∫°y app\n",
        "demo.launch(share=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "tQiKBpMclP8m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}