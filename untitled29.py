# -*- coding: utf-8 -*-
"""Untitled29.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OVVVMGu68TWg-FD7C-tUJB09iA9hkosJ
"""

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 1) Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

import os
src_path = "/content/drive/MyDrive/Palmistry"

# Ki·ªÉm tra th∆∞ m·ª•c
print("Classes:", os.listdir(src_path))

# 2) Import + t·∫°o generator v·ªõi resize 60x60 v√† t√°ch validation 20%
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.5,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_generator = datagen.flow_from_directory(
    src_path,
    target_size=(60, 60),
    batch_size=32,
    class_mode='categorical',
    subset='training',   # train subset
    shuffle=True
)

val_generator = datagen.flow_from_directory(
    src_path,
    target_size=(60, 60),
    batch_size=32,
    class_mode='categorical',
    subset='validation',  # validation subset
    shuffle=False
)

# 3) Build CNN model
from tensorflow.keras import layers, models

num_classes = train_generator.num_classes

model = models.Sequential([
    layers.Input(shape=(60, 60, 3)),
    layers.Conv2D(32, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

# 4) Train model
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=200
)
model.save('final_model.h5')

from google.colab import files
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Upload ·∫£nh
uploaded = files.upload()
img_path = list(uploaded.keys())[0]

# ƒê·ªçc + resize v·ªÅ 60x60
img = cv2.imread(img_path)
img_resized = cv2.resize(img, (60, 60))
img_array = img_resized / 255.0
img_array = np.expand_dims(img_array, axis=0)

# D·ª± ƒëo√°n
pred = model.predict(img_array)
class_index = np.argmax(pred)
confidence = np.max(pred)

labels = list(train_generator.class_indices.keys())
print("D·ª± ƒëo√°n:", labels[class_index], "- ƒê·ªô tin c·∫≠y:", confidence)

# Hi·ªÉn th·ªã ·∫£nh
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.title(f"D·ª± ƒëo√°n: {labels[class_index]} ({confidence:.2f})")
plt.axis("off")
plt.show()

import gradio as gr
import numpy as np
from PIL import Image
from tensorflow.keras.models import load_model

# Load model CNN nh·∫≠n di·ªán ch·ªâ tay
model_path = 'final_model.h5'  # ƒë·ªïi theo ƒë∆∞·ªùng d·∫´n model c·ªßa b·∫°n
model = load_model(model_path)

# Nh√£n c√°c lo·∫°i ch·ªâ tay (th·ª© t·ª± ph·∫£i tr√πng v·ªõi model training)
palm_labels = [
    "Ch·ªâ tay ch·ªØ M",
    "Ch·ªâ tay ch·ªØ nh·∫•t",
    "Ch·ªâ tay ƒëu√¥i c√°",
    "Ch·ªâ tay m·∫Øt ph∆∞·ª£ng",
    "Ch·ªâ tay th·ªèi v√†ng"
]

# Th√¥ng tin chi ti·∫øt v·ªÅ t·ª´ng lo·∫°i ch·ªâ tay
palmistry_info = {
    "Ch·ªâ tay ch·ªØ M": "Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay ch·ªØ M th∆∞·ªùng ƒë∆∞·ª£c cho l√† c√≥ t√†i nƒÉng ƒë·∫∑c bi·ªát, th√¥ng minh, v√† may m·∫Øn. H·ªç c√≥ kh·∫£ nƒÉng l√£nh ƒë·∫°o, tr·ª±c gi√°c t·ªët v√† th∆∞·ªùng ƒë·∫°t ƒë∆∞·ª£c th√†nh c√¥ng l·ªõn trong s·ª± nghi·ªáp v√† cu·ªôc s·ªëng.",
    "Ch·ªâ tay ch·ªØ nh·∫•t": "Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay ch·ªØ Nh·∫•t th∆∞·ªùng c√≥ t√≠nh c√°ch m·∫°nh m·∫Ω v√† quy·∫øt ƒëo√°n. H·ªç c√≥ kh·∫£ nƒÉng t·∫≠p trung cao ƒë·ªô v√† th∆∞·ªùng ƒë·∫°t ƒë∆∞·ª£c th√†nh c√¥ng trong nh·ªØng lƒ©nh v·ª±c ƒë√≤i h·ªèi s·ª± ki√™n tr√¨ v√† quy·∫øt t√¢m. Tuy nhi√™n, h·ªç c≈©ng c√≥ th·ªÉ g·∫∑p kh√≥ khƒÉn trong vi·ªác c√¢n b·∫±ng gi·ªØa l√Ω tr√≠ v√† c·∫£m x√∫c.",
    "Ch·ªâ tay ƒëu√¥i c√°": "Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay ƒëu√¥i c√° th∆∞·ªùng ƒë∆∞·ª£c coi l√† c√≥ may m·∫Øn ƒë·∫∑c bi·ªát v√† th∆∞·ªùng g·∫∑p ƒë∆∞·ª£c nhi·ªÅu c∆° h·ªôi t·ªët trong cu·ªôc s·ªëng. H·ªç c√≥ kh·∫£ nƒÉng v∆∞·ª£t qua kh√≥ khƒÉn v√† ƒë·∫°t ƒë∆∞·ª£c th√†nh c√¥ng l·ªõn.",
    "Ch·ªâ tay m·∫Øt ph∆∞·ª£ng": "Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay m·∫Øt ph∆∞·ª£ng th∆∞·ªùng c√≥ tr·ª±c gi√°c t·ªët, tr√≠ tu·ªá cao v√† kh·∫£ nƒÉng nh√¨n xa tr√¥ng r·ªông. H·ªç th∆∞·ªùng ƒë∆∞·ª£c qu√Ω nh√¢n ph√π tr·ª£ v√† c√≥ nhi·ªÅu c∆° h·ªôi th√†nh c√¥ng trong cu·ªôc s·ªëng.",
    "Ch·ªâ tay th·ªèi v√†ng": "Ng∆∞·ªùi c√≥ ƒë∆∞·ªùng ch·ªâ tay th·ªèi v√†ng th∆∞·ªùng ƒë∆∞·ª£c cho l√† c√≥ t√†i l·ªôc, th·ªãnh v∆∞·ª£ng v√† th√†nh c√¥ng trong s·ª± nghi·ªáp. H·ªç c√≥ kh·∫£ nƒÉng qu·∫£n l√Ω t√†i ch√≠nh t·ªët v√† th∆∞·ªùng g·∫∑p may m·∫Øn trong kinh doanh.",
}

# H√†m d·ª± ƒëo√°n
def predict_palm(img):
    img_resized = img.convert("RGB").resize((60,60))  # Resize v·ªÅ 60x60 (theo model b·∫°n train)
    x = np.array(img_resized)/255.0
    x = np.expand_dims(x, axis=0)
    preds = model.predict(x)
    class_idx = np.argmax(preds)
    confidence = preds[0][class_idx]

    palm_type = palm_labels[class_idx]
    description = palmistry_info.get(palm_type, "Ch∆∞a c√≥ th√¥ng tin.")
    return img_resized, palm_type, round(confidence*100, 2), description

# H√†m reset
def reset_image():
    return None, None, "", "", ""

# CSS giao di·ªán huy·ªÅn b√≠
css_style = """
body {
    background: radial-gradient(circle at top, #1c0033, #0a0014);
    font-family: 'Poppins', sans-serif;
    color: #f3e5f5;
}
h1 {
    color: #ffffff;  /* tr·∫Øng s√°ng thay v√¨ t√≠m nh·∫°t */
    text-shadow: 0px 0px 20px #e1bee7, 0px 0px 40px #ba68c8;
    font-family: 'Orbitron', sans-serif;
    font-size: 42px;
    font-weight: bold;
    letter-spacing: 2px;
}
#predict-btn {
    background: linear-gradient(45deg, #6a1b9a, #311b92);
    color: #fff;
    font-weight: bold;
    font-size: 18px;
    border-radius: 25px;
    box-shadow: 0px 0px 10px #7e57c2;
}
#reset-btn {
    background: linear-gradient(45deg, #004d40, #1a237e);
    color: #fff;
    font-weight: bold;
    font-size: 18px;
    border-radius: 25px;
    box-shadow: 0px 0px 10px #26a69a;
}
.gr-button {padding: 12px 25px;}
.gr-box {
    border: 2px solid #7e57c2;
    border-radius: 20px;
    padding: 15px;
    background-color: rgba(20, 0, 40, 0.85);
    color: #e1bee7;
}
"""

# Giao di·ªán Gradio
with gr.Blocks(css=css_style) as demo:
    gr.Markdown("<h1 style='text-align:center;'>üîÆ ·ª®ng d·ª•ng b√≥i ch·ªâ tay online ‚úã</h1>")

    with gr.Row():
        with gr.Column():
            img_input = gr.Image(type="pil", label="‚ú® Ch·ªçn ·∫£nh ho·∫∑c k√©o th·∫£ ·∫£nh ch·ªâ tay ‚ú®")
            btn_predict = gr.Button("üîÆ Nh·∫≠n di·ªán ‚úã", elem_id="predict-btn")
            btn_reset = gr.Button("üîÑ Ch·ªçn ·∫£nh kh√°c", elem_id="reset-btn")
        with gr.Column():
            label_output = gr.Textbox(label="üîÆ Lo·∫°i ch·ªâ tay d·ª± ƒëo√°n", interactive=False)
            confidence_output = gr.Textbox(label="üìä ƒê·ªô ch√≠nh x√°c (%)", interactive=False)
            description_output = gr.Textbox(label="üìñ Mi√™u t·∫£ chi ti·∫øt", interactive=False, lines=6)

    # N√∫t d·ª± ƒëo√°n
    btn_predict.click(
        predict_palm,
        inputs=img_input,
        outputs=[img_resized_output, label_output, confidence_output, description_output]
    )

    # N√∫t reset
    btn_reset.click(
        reset_image,
        inputs=None,
        outputs=[img_input, img_resized_output, label_output, confidence_output, description_output]
    )

# Ch·∫°y app
demo.launch(share=True)